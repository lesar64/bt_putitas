{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd        \n",
    "import tensorflow.compat.v1 as tf \n",
    "tf.disable_v2_behavior()\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "c:\\users\\janfd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "c:\\users\\janfd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\janfd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\janfd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n",
      "c:\\users\\janfd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n",
      "c:\\users\\janfd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "c:\\users\\janfd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\janfd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "in_train_df = pd.read_hdf('df_train_in.h5', key='df')\n",
    "in_train_matrix = in_train_df[['Month', 'Day', 'Weekday', 'Hours', 'Minutes', 'Temp', 'Precip', '-10']].as_matrix()\n",
    "x1_train_matrix = in_train_df[['-5']].as_matrix()\n",
    "x2_train_matrix = in_train_df[['Now']].as_matrix()\n",
    "out_train_matrix = pd.read_hdf('df_train_out.h5', key = 'df').as_matrix()\n",
    "in_eval_df = pd.read_hdf('df_evalu_in.h5', key='df')\n",
    "in_eval_matrix = in_eval_df[['Month', 'Day', 'Weekday', 'Hours', 'Minutes', 'Temp', 'Precip', '-10']].as_matrix()\n",
    "x1_eval_matrix = in_eval_df[['-5']].as_matrix()\n",
    "x2_eval_matrix = in_eval_df[['Now']].as_matrix()\n",
    "out_eval_matrix = pd.read_hdf('df_evalu_out.h5', key = 'df').as_matrix()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "in_train, in_test, out_train, out_test, x1_train, x1_test, x2_train, x2_test = train_test_split(\n",
    "    in_train_matrix, out_train_matrix, x1_train_matrix, x2_train_matrix, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Python optimisation variables\n",
    "epochs = 25\n",
    "batch_size = 100\n",
    "\n",
    "# Define Input and Output\n",
    "inp = tf.placeholder(tf.float32, [None, 8], name='input')\n",
    "out = tf.placeholder(tf.float32, [None, 1], name='Output')\n",
    "x1 = tf.placeholder(tf.float32, [None, 1], name='x1')\n",
    "x2 = tf.placeholder(tf.float32, [None, 1], name='x2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Scale Layer\n",
    "w0 = tf.Variable(tf.random_normal([8, 10], stddev=0.03), name='w0')\n",
    "b0 = tf.Variable(tf.random_normal([10]), name='b0')\n",
    "\n",
    "y0 = tf.add(tf.matmul(inp, w0), b0)\n",
    "\n",
    "# First Layer\n",
    "w1 = tf.Variable(tf.random_normal([10, 10], stddev=0.03), name='w1')\n",
    "b1 = tf.Variable(tf.random_normal([1, 10]), name='b1')\n",
    "\n",
    "# y1 = tf.nn.relu(tf.add(tf.matmul(inp, w1), b1))\n",
    "y1 = tf.log_sigmoid(tf.add(tf.matmul(x1, b1), tf.matmul(y0, w1)))\n",
    "\n",
    "# Second Layer\n",
    "w2 = tf.Variable(tf.random_normal([10, 10], stddev=0.03), name='w2')\n",
    "b2 = tf.Variable(tf.random_normal([1, 10]), name='b2')\n",
    "\n",
    "# y2 = tf.nn.relu(tf.add(tf.matmul(y1, w2), b2))\n",
    "y2 = tf.log_sigmoid(tf.add(tf.matmul(x2, b2), tf.matmul(y1, w2)))\n",
    "\n",
    "# Output Layer\n",
    "wo = tf.Variable(tf.random_normal([10, 1], stddev=0.03), name='wo')\n",
    "bo = tf.Variable(tf.random_normal([1]), name='bo')\n",
    "\n",
    "# yo = tf.nn.softmax(tf.add(tf.matmul(y2, wo), bo))\n",
    "# yo = tf.nn.relu(tf.add(tf.matmul(y2, wo), bo))\n",
    "yo = tf.add(tf.matmul(y2, wo), bo)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "cross_entropy = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(out, yo)))) #RMSE\n",
    "# cross_entropy = tf.reduce_mean(tf.square(out - yo)) #MSE\n",
    "\n",
    "# Optimizer\n",
    "# optimiser = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "optimiser = tf.train.AdamOptimizer().minimize(cross_entropy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Initialisation Operator\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Accuracy (same as Loss)\n",
    "constant_one = tf.constant(1.0, name=\"const_one\")\n",
    "# correct_prediction = tf.equal(tf.argmax(out, 1), tf.argmax(yo, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# accuracy = tf.reduce_mean(tf.cast(tf.abs(tf.subtract(yo, out)), tf.float32))\n",
    "# accuracy = tf.reduce_mean(tf.cast(tf.subtract(constant_one, tf.abs(tf.subtract(yo, out))), tf.float32))\n",
    "# accuracy =  tf.reduce_mean(tf.abs(tf.cast(tf.subtract(constant_one,tf.sqrt(tf.reduce_mean(\n",
    "#     tf.square(tf.subtract(out, yo))))), tf.float32)))\n",
    "accuracy =  (tf.subtract(constant_one,tf.sqrt(tf.reduce_mean(tf.square(\n",
    "    tf.subtract(out, tf.clip_by_value(yo, 0, 1)))))))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# accuracy_data = np.empty(epochs)\n",
    "# \n",
    "# # Start Session\n",
    "# with tf.Session() as sess:\n",
    "#     # initialise the variables\n",
    "#     sess.run(init_op)\n",
    "#     total_batch = int(len(in_train) / batch_size) #in_train\n",
    "#     acc_train = accuracy.eval(session= sess, feed_dict={inp: in_train, out: out_train, x1: x1_train, x2: x2_train})\n",
    "#     print(\"Beginning accuracy: {:3.2f}%\".format(acc_train*100.0))\n",
    "#     for epoch in range(epochs):\n",
    "#         avg_cost = 0\n",
    "#         for i in range(total_batch):\n",
    "#             batch_in = in_train[i*batch_size:(i+1)*batch_size]\n",
    "#             batch_out = out_train[i*batch_size:(i+1)*batch_size]\n",
    "#             batch_x1 = x1_train[i*batch_size:(i+1)*batch_size]\n",
    "#             batch_x2 = x2_train[i*batch_size:(i+1)*batch_size]\n",
    "# \n",
    "#             _, c = sess.run([optimiser, cross_entropy], \n",
    "#                             feed_dict={inp: batch_in, out: batch_out, x1: batch_x1, x2: batch_x2})\n",
    "# \n",
    "#             avg_cost += c / total_batch\n",
    "#         print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost))\n",
    "# \n",
    "#         # Save Accuracy over Iterations\n",
    "#         acc_train = accuracy.eval(session= sess, feed_dict={inp: in_train, out: out_train, x1: x1_train, x2: x2_train})\n",
    "#         print(\"Accuracy: {:3.2f}%\".format(acc_train*100.0))\n",
    "#         accuracy_data[epoch] = acc_train\n",
    "# \n",
    "#     # Calculate Accuracy on Train and Test\n",
    "#     acc_train = accuracy.eval(session= sess, feed_dict={inp: in_train, out: out_train, x1: x1_train, x2: x2_train})\n",
    "#     print(\"Train accuracy: {:3.2f}%\".format(acc_train*100.0))\n",
    "# \n",
    "#     acc_test = accuracy.eval(session= sess, feed_dict={inp: in_test, out: out_test, x1: x1_test, x2: x2_test})\n",
    "#     print(\"Test accuracy:  {:3.2f}%\".format(acc_test*100.0))\n",
    "# \n",
    "#     # Evaluate\n",
    "#     acc_eval = accuracy.eval(session= sess, feed_dict={inp: in_eval_matrix, out: out_eval_matrix, x1: x1_eval_matrix, x2: x2_eval_matrix})\n",
    "#     print(\"Eval accuracy:  {:3.2f}%\".format(acc_eval*100.0))    \n",
    "# \n",
    "#     # Save Dataframe with Accuracy over Iterations\n",
    "#     acc_iter = pd.DataFrame({'Accuracy': accuracy_data}).to_hdf('df_acc_rnn.h5',key='df', mode='w')\n",
    "# \n",
    "#     # Save Dataframe with Predictions for Evaluation Dataset\n",
    "#     predictions = pd.DataFrame(sess.run(yo,feed_dict={inp: in_eval_matrix, out: out_eval_matrix, x1: x1_eval_matrix, x2: x2_eval_matrix}), columns=['Prediction'])\\\n",
    "#         .to_hdf('df_evalu_pred_rnn.h5',key='df', mode='w')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Eval accuracy:  95.34%\n",
      "Eval accuracy:  95.29%\n",
      "Eval accuracy:  95.34%\n",
      "Eval accuracy:  95.34%\n",
      "Eval accuracy:  95.31%\n",
      "Eval accuracy:  95.30%\n",
      "Eval accuracy:  95.30%\n",
      "Eval accuracy:  95.33%\n",
      "Eval accuracy:  95.35%\n",
      "Eval accuracy:  95.31%\n",
      "Eval accuracy:  95.25%\n",
      "Eval accuracy:  95.33%\n",
      "Eval accuracy:  95.32%\n",
      "Eval accuracy:  95.32%\n",
      "Eval accuracy:  95.35%\n",
      "Eval accuracy:  95.23%\n",
      "Eval accuracy:  95.31%\n",
      "Eval accuracy:  95.34%\n",
      "Eval accuracy:  95.32%\n",
      "Eval accuracy:  95.33%\n",
      "Mean Eval accuracy:  95.32%\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Loop to get a mean Accuracy\n",
    "acc_all = 0.0\n",
    "acc_iter = pd.DataFrame(index=range(epochs),columns=['Accuracy']).fillna(value=0)\n",
    "n = 20 #20\n",
    "for mean_iter in range(n):\n",
    "\n",
    "    accuracy_data = np.empty(epochs)\n",
    "\n",
    "    # Start Session\n",
    "    with tf.Session() as sess:\n",
    "        # initialise the variables\n",
    "        sess.run(init_op)\n",
    "        total_batch = int(len(in_train) / batch_size) #in_train\n",
    "        # acc_train = accuracy.eval(session= sess, feed_dict={inp: in_train, out: out_train, x1: x1_train, x2: x2_train})\n",
    "        # print(\"Beginning accuracy: {:3.2f}%\".format(acc_train*100.0))\n",
    "        for epoch in range(epochs):\n",
    "            avg_cost = 0\n",
    "            for i in range(total_batch):\n",
    "                batch_in = in_train[i*batch_size:(i+1)*batch_size]\n",
    "                batch_out = out_train[i*batch_size:(i+1)*batch_size]\n",
    "                batch_x1 = x1_train[i*batch_size:(i+1)*batch_size]\n",
    "                batch_x2 = x2_train[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "                _, c = sess.run([optimiser, cross_entropy], \n",
    "                                feed_dict={inp: batch_in, out: batch_out, x1: batch_x1, x2: batch_x2})\n",
    "\n",
    "            #     avg_cost += c / total_batch\n",
    "            # print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost))\n",
    "\n",
    "            # Save Accuracy over Iterations\n",
    "            acc_train = accuracy.eval(session= sess, feed_dict={inp: in_train, out: out_train, x1: x1_train, x2: x2_train})\n",
    "            # print(\"Accuracy: {:3.2f}%\".format(acc_train*100.0))\n",
    "            accuracy_data[epoch] = acc_train\n",
    "\n",
    "        # # Calculate Accuracy on Train and Test\n",
    "        # acc_train = accuracy.eval(session= sess, feed_dict={inp: in_train, out: out_train, x1: x1_train, x2: x2_train})\n",
    "        # print(\"Train accuracy: {:3.2f}%\".format(acc_train*100.0))\n",
    "        # \n",
    "        # acc_test = accuracy.eval(session= sess, feed_dict={inp: in_test, out: out_test, x1: x1_test, x2: x2_test})\n",
    "        # print(\"Test accuracy:  {:3.2f}%\".format(acc_test*100.0))\n",
    "        # \n",
    "        # # Evaluate\n",
    "        acc_eval = accuracy.eval(session= sess, feed_dict={inp: in_eval_matrix, out: out_eval_matrix, x1: x1_eval_matrix, x2: x2_eval_matrix})\n",
    "        print(\"Eval accuracy:  {:3.2f}%\".format(acc_eval*100.0))    \n",
    "        acc_all += acc_eval\n",
    "\n",
    "        # Save Dataframe with Accuracy over Iterations\n",
    "        acc_iter['Accuracy'] = acc_iter['Accuracy'] + accuracy_data\n",
    "\n",
    "# Mean Accuracy\n",
    "print(\"Mean Eval accuracy:  {:3.2f}%\".format((acc_all/n)*100.0)) \n",
    "\n",
    "\n",
    "# Save Mean Accuracy per Iteration\n",
    "acc_iter['Accuracy'] = acc_iter['Accuracy'].divide(n)\n",
    "pd.DataFrame(acc_iter['Accuracy']).to_hdf('df_acc_rnn_mean.h5',key='df', mode='w') \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}